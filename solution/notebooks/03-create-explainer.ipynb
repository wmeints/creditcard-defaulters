{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Create explainers\n",
    "\n",
    "In the previous part we've trained and validated a model, but can we really trust it? Often, when a model predicts the wrong thing, you're left wondering, why did it make this decision? This is where explainers can help out. Ultimately, explainers help you build trust. \n",
    "\n",
    "In this notebook we're going to train an explainer and use it to explore the model. We'll cover the following topics:\n",
    "\n",
    "* [Loading the trained model](#loading-the-trained-model)\n",
    "* [Loading the test dataset](#loading-the-test-dataset)\n",
    "* [Creating a blackbox performance explainer](#creating-a-blackbox-performance-explainer)\n",
    "* [Creating a blackbox model explainer](#creating-a-blackbox-model-explainer)\n",
    "* [Creating a local model explainer](#creating-a-local-model-explainer)\n",
    "\n",
    "Unlike the previous steps of the tutorial, this step contains prefilled code as explainers is a complete course on its own.\n",
    "\n",
    "Let's get started by loading the trained model from the previous step in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model\n",
    "\n",
    "In the previous step we've saved our model using joblib. Let's load it back up again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = joblib.load('../models/classifier.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model, let's load up a testing set to create the explainers for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test dataset\n",
    "\n",
    "We're going to use the test dataset, as it provides the best independent explanations for the model.\n",
    "Let's use pandas to load up the dataset and extract the features and outputs of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/processed/train.csv')\n",
    "df_test = pd.read_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'LIMIT_BAL',\n",
    "    'SEX',\n",
    "    'EDUCATION',\n",
    "    'MARRIAGE',\n",
    "    'AGE',\n",
    "    'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "    'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "    'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    "]\n",
    "\n",
    "target_name = 'default.payment.next.month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test[feature_names]\n",
    "y_test = df_test[target_name]\n",
    "x_train = df_train[feature_names]\n",
    "y_train = df_train[target_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset loaded, let's take a look at the first explainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a blackbox performance explainer\n",
    "The first explainer we're going to create is a performance explainer. This performance explainer provides you with insights into how the performance of the model came to be. We're using an [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.perf import ROC\n",
    "from interpret import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<!-- http://127.0.0.1:7873/1912517887496/ -->\n<iframe src=\"http://127.0.0.1:7873/1912517887496/\" width=100% height=800 frameBorder=\"0\"></iframe>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "explain_perf = ROC(classifier.predict_proba, feature_names=feature_names).explain_perf(x_test, y_test, name='Performance')\n",
    "show(explain_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance explainer shows the Receiver Operator Curve as we've used it in the previous step of the tutorial. Here's how to interpret it.\n",
    "\n",
    "### Interpreting the ROC curve (Top chart)\n",
    "At the top there's the ROC curve. The orange line represents the classifier as we trained it.\n",
    "The y-axis represents the percentage of values correctly predicted (true-positive rate)\n",
    "The x-axis represents the percentagee of values incorrectly predicted as 1 (false-positive rate).\n",
    "\n",
    "The orange line should follow a course as close as possible to the top left corner. Meaning that we have 0% false positives and 100% true positives.\n",
    "In this case it won't, because the model contains errors picked up from the input data.\n",
    "\n",
    "### Interpreting the histogram (Bottom chart)\n",
    "Underneath the first chart, there's a histogram for the predictions. It shows a distribution of the predicted outcomes.\n",
    "You can use this to see how well the model splits between 0 and 1. Note that values below 0.5 are rounded to 0 and values above 0.5 to 1 when you use the   \n",
    "model in your application.\n",
    "\n",
    "In this case you'll see a high number of predictions close to zero and a lower number of predictions close to zero. Finally, there's a wide variety of predictions that fall in between the two classes that we specified. This means our classifier is unsure what to do in quite a lot of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen the performance, let's see what features have the most effect on the outcome of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a blackbox model explainer\n",
    "Let's explore our model further using a blackbox explainer. We're going to visualize what features have the most effect on the output of the model overall.\n",
    "For this, we can use the MorrisSensitivity explainer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import MorrisSensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<!-- http://127.0.0.1:7873/1912555222024/ -->\n<iframe src=\"http://127.0.0.1:7873/1912555222024/\" width=100% height=800 frameBorder=\"0\"></iframe>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "explain_global = MorrisSensitivity(classifier.predict_proba, x_train, feature_names=feature_names).explain_global(name='Sensitivity')\n",
    "show(explain_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart shows the relative impact of a feature in the output of the model. This chart should be interpreted as follows:\n",
    "\n",
    "Each feature has a value (mouse over it, you can read it) it adds to the output or subtracts from the output.\n",
    "This value in this case is really small, since we're dealing with a scale from 0 to 1.\n",
    "\n",
    "In practice, you can look at this chart and see that the PAY_0 column has the most influence on the outcome of the model.\n",
    "\n",
    "In the case of our model we could say that:\n",
    "\n",
    "* If you ever missed a payment in the first month, it's more likely it will happen again.\n",
    "* The difference in value between `PAY_0` and `PAY_2` is not that large, which means that when you miss your second payment, \n",
    "  it's even more likely you'll miss a payment again in the future. The effect of the length of missed payment terms is diminishing over time.\n",
    "* After the payment terms, we see that age also has an effect.\n",
    "\n",
    "Given the explainer, we can see that it's probably best to just look at information about missed payments in the past, rather than age, gender, and education level. Which makes sense when you apply common sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an overall explanation of our model, we can start to zoom in on individual cases. Let's explore a local explainer next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a local model explainer\n",
    "Customers often want to know, why did the model make this prediction especially when the model produces the wrong output.\n",
    "Using a local explainer, you can see why a model produced a certain outcome for specific inputs.\n",
    "\n",
    "We're using the LIME explainer for this purpose. It allows us to see the impact of input features on a specific outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import LimeTabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_local = LimeTabular(classifier.predict_proba, x_train, feature_names=feature_names).explain_local(x_test.iloc[:5,:], y_test.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<!-- http://127.0.0.1:7873/1912515857096/ -->\n<iframe src=\"http://127.0.0.1:7873/1912515857096/\" width=100% height=800 frameBorder=\"0\"></iframe>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "show(explain_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: To view individual explanations, select a prediction from the dropdown in the widget.\n",
    "\n",
    "The local explainer helps you understand the impact of the various input values on the outcome of the model for a single sample.\n",
    "Please note that the feature importance might be quite different from the global explanation, because the global explanation assumes a lot about the shape of the data. It uses information about the mean and standard deviation of the features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we've used various explainers to get a better understanding of the model in relation to the data that was used to train and validate the model. As you've noticed, you'll need different explainers to answer different questions:\n",
    "\n",
    "* Use performance explainers to understand the overall performance.\n",
    "* Use global explainers to get a sense of what features are most important for your model.\n",
    "* Use local explainers to understand why a certain case produced an (un)expected output.\n",
    "\n",
    "We hope you liked this tutorial! If you have any questions, don't hesitate to leave an issue on github or drop a note on twitter @willem_meints."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitec1935bbcb5841e2bfd70a81b7fc8416",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}