{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Prepare data\n",
    "\n",
    "Imagine you're working for a new credit card company that wants to take a data-driven approach to providing credit card loans to customers.\n",
    "As part of your data-driven approach you want to use a model that's going to predict whether a customer is going to default\n",
    "their next credit card payment. Based on this model you want to provide additional services to customers, like providing help\n",
    "with their financial situation.\n",
    "\n",
    "In this first part of the tutorial we're going to prepare a dataset for the machine learning model.\n",
    "We'll cover the following topics:\n",
    "\n",
    "* [Loading data using pandas](#loading-data-using-pandas)\n",
    "* [Creating a training and testing dataset](#creating-a-and-testing-dataset)\n",
    "* [Storing the dataset on disk](#storing-the-dataset-on-disk)\n",
    "\n",
    "Let's get started by loading the raw dataset from disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data using pandas\n",
    "The model that we're about to train uses a a dataset that's stored in `../data/raw/UCI_Credit_card.csv`. \n",
    "Let's load it up and see what it looks like:\n",
    "\n",
    "* First, import the pandas package (already done for you)\n",
    "* Next, use the function [pd.read_csv(...)]() to load the dataset and assign it to `df_creditcard`. \n",
    "* Finally, call `df_creditcard.info()` to get some insights into what is in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_creditcard = pd.read_csv('../data/raw/UCI_Credit_card.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have a dataset in memory that we can use to train.\n",
    "From the info method call you'll have gathered that the total dataset contains 30K samples, which is quite enough to train a model.\n",
    "\n",
    "Now that we have loaded the dataset, let's create a test and training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a training and a testing dataset\n",
    "In the previous section we've loaded the dataset from disk. We could use this dataset for training without problems.\n",
    "If we were to use the whole dataset for training we would be unable to validate that the model is actually working, because we have no independent dataset to test the model.\n",
    "\n",
    "In this section we're going to split the dataset. Perform the following steps:\n",
    "\n",
    "* First, import the function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from scikit-learn (already done for you).\n",
    "* Next, split the dataset using the train_test_split function. Use `test_size=0.1` to specify the percentage of data to include in the test dataset. Store the result in `df_train` and `df_test`. (Note: You can assign the output of a function to multiple variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_creditcard, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training and testing dataset, let's save them for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the dataset on disk\n",
    "In the previous sections we've spend some time getting our data ready. In this section we're going to store the data on disk for using during the next part of the tutorial.\n",
    "Follow these steps to store your datasets on disk:\n",
    "\n",
    "* First, use the [to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) method on `df_train` to store it on disk. \n",
    "  specify the filename (`../data/processed/train.csv`) \n",
    "  and include `index=None` as an additional parameter.\n",
    "* Next, repeat the previous step for `df_test`, but store it in `../data/processed/test.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../data/processed/train.csv', index=None)\n",
    "df_test.to_csv('../data/processed/test.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! In this first part of the tutorial you've made a dataset suitable for training a machine learning model. You've also made sure that you can test your machine learning once you've trained it. \n",
    "\n",
    "In the [next part](./02-train-model.ipynb), we're going to take a look at training a machine learning model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitec1935bbcb5841e2bfd70a81b7fc8416",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}